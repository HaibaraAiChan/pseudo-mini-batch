main start at this time 1649750035.7344396
-----------------------------------------before load data 
 Nvidia-smi: 1.1785888671875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

karate data
#nodes: 34
#edges: 156
#classes: 2
success----------------------------------------
24
5
5
# Nodes: 34
# Edges: 156
# Train: 24
# Val: 5
# Test: 5
# Classes: 2

in feats:  4
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 2.0242919921875 GB
    Memory Allocated: 0.0005083084106445312  GigaBytes
Max Memory Allocated: 0.0005083084106445312  GigaBytes

*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
[Block(num_src_nodes=33, num_dst_nodes=33, num_edges=65), Block(num_src_nodes=33, num_dst_nodes=30, num_edges=78), Block(num_src_nodes=30, num_dst_nodes=24, num_edges=70)]
global src and dst nids
tensor([18,  9,  2,  8, 20, 19, 14,  5,  0, 15, 21,  7, 12, 22, 11, 23, 16, 13,
        17,  1,  3, 10,  6,  4, 32, 33, 27, 30, 25, 29, 26, 24, 31])
tensor([18,  9,  2,  8, 20, 19, 14,  5,  0, 15, 21,  7, 12, 22, 11, 23, 16, 13,
        17,  1,  3, 10,  6,  4, 32, 33, 27, 30, 25, 29, 26, 24, 31])
global src and dst nids
tensor([18,  9,  2,  8, 20, 19, 14,  5,  0, 15, 21,  7, 12, 22, 11, 23, 16, 13,
        17,  1,  3, 10,  6,  4, 32, 33, 27, 30, 25, 29, 26, 24, 31])
tensor([18,  9,  2,  8, 20, 19, 14,  5,  0, 15, 21,  7, 12, 22, 11, 23, 16, 13,
        17,  1,  3, 10,  6,  4, 32, 33, 27, 30, 25, 29])
global src and dst nids
tensor([18,  9,  2,  8, 20, 19, 14,  5,  0, 15, 21,  7, 12, 22, 11, 23, 16, 13,
        17,  1,  3, 10,  6,  4, 32, 33, 27, 30, 25, 29])
tensor([18,  9,  2,  8, 20, 19, 14,  5,  0, 15, 21,  7, 12, 22, 11, 23, 16, 13,
        17,  1,  3, 10,  6,  4])
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.002461671829223633
src global
[18, 9, 2, 8, 20, 19, 14, 5, 0, 15, 21, 7, 12, 22, 11, 23, 16, 13, 17, 1, 3, 10, 6, 4, 32, 33, 27, 30, 25, 29]
dst local
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]
global_2_local spend time (sec) 8.20159912109375e-05
----------------------------  graph partition start---------------------
  (8, 1)	1
  (19, 1)	1
  (26, 1)	1
  (8, 2)	1
  (10, 2)	1
  (12, 2)	1
  (19, 2)	1
  (20, 2)	1
  (22, 2)	1
  (25, 2)	1
  (27, 2)	1
  (1, 3)	1
  (8, 3)	1
  (12, 3)	1
  (19, 3)	2
  (20, 3)	1
  (22, 3)	1
  (26, 3)	1
  (2, 5)	1
  (8, 5)	1
  (10, 5)	1
  (12, 5)	1
  (19, 5)	1
  (20, 5)	1
  (22, 5)	1
  :	:
  (8, 20)	3
  (12, 20)	1
  (19, 20)	3
  (22, 20)	1
  (26, 20)	1
  (8, 21)	2
  (12, 21)	1
  (16, 21)	1
  (19, 21)	1
  (20, 21)	1
  (22, 21)	3
  (7, 22)	1
  (8, 22)	2
  (12, 22)	1
  (16, 22)	1
  (19, 22)	1
  (20, 22)	1
  (21, 22)	2
  (7, 23)	2
  (8, 23)	2
  (12, 23)	1
  (16, 23)	1
  (19, 23)	1
  (20, 23)	1
  (22, 23)	1
     source  target  weight  capacity
0         8       1       1         1
1        19       1       1         1
2         8       2       1         1
3        10       2       1         1
4        12       2       1         1
..      ...     ...     ...       ...
107      12      23       1         1
108      16      23       1         1
109      19      23       1         1
110      20      23       1         1
111      22      23       1         1

[112 rows x 4 columns]

6
({1}, {2, 3, 5, 7, 8, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23})
#### TODO change this to global to check them on html graph 
after graph partition
graph partition algorithm spend time 0.04474139213562012
partition_len_list
[3, 21]
shared_neighbor_graph_partition selection method range initialization spend 0.0452120304107666
time for parepare:  6.9141387939453125e-06
local_output_nid generation:  2.6226043701171875e-06
local_in_edges_tensor generation:  0.00012302398681640625
mini_batch_src_global generation:  3.3855438232421875e-05
r_  generation:  0.0006885528564453125
local_output_nid generation:  3.0994415283203125e-06
local_in_edges_tensor generation:  0.0001506805419921875
mini_batch_src_global generation:  3.814697265625e-05
r_  generation:  4.267692565917969e-05
----------------------check_connections_block total spend ----------------------------- 0.0012903213500976562
generate_one_block  0.003072977066040039
generate_one_block  0.0012521743774414062
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0004792213439941406
gen group dst list time:  1.8358230590820312e-05
time for parepare:  1.3113021850585938e-05
local_output_nid generation:  1.6689300537109375e-06
local_in_edges_tensor generation:  0.0001647472381591797
mini_batch_src_global generation:  2.0265579223632812e-05
r_  generation:  1.9788742065429688e-05
local_output_nid generation:  3.5762786865234375e-06
local_in_edges_tensor generation:  0.00010538101196289062
mini_batch_src_global generation:  2.0503997802734375e-05
r_  generation:  3.361701965332031e-05
----------------------check_connections_block total spend ----------------------------- 0.00047898292541503906
generate_one_block  0.0011610984802246094
generate_one_block  0.001172780990600586
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.00041675567626953125
gen group dst list time:  1.8358230590820312e-05
time for parepare:  7.62939453125e-06
local_output_nid generation:  2.1457672119140625e-06
local_in_edges_tensor generation:  0.00015878677368164062
mini_batch_src_global generation:  2.0503997802734375e-05
r_  generation:  2.193450927734375e-05
local_output_nid generation:  2.86102294921875e-06
local_in_edges_tensor generation:  0.00010752677917480469
mini_batch_src_global generation:  1.6689300537109375e-05
r_  generation:  3.337860107421875e-05
----------------------check_connections_block total spend ----------------------------- 0.00047516822814941406
generate_one_block  0.001123189926147461
generate_one_block  0.0012288093566894531
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 2.0242919921875 GB
    Memory Allocated: 0.0005083084106445312  GigaBytes
Max Memory Allocated: 0.0005083084106445312  GigaBytes

connection checking time:  0.0009541511535644531
block generation total time  0.004685878753662109
average batch blocks generation time:  0.0023429393768310547
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.0887451171875 GB
    Memory Allocated: 0.0005121231079101562  GigaBytes
Max Memory Allocated: 0.0005121231079101562  GigaBytes

----------------------------------------before model layer 0
 Nvidia-smi: 2.0887451171875 GB
    Memory Allocated: 0.0005121231079101562  GigaBytes
Max Memory Allocated: 0.0005121231079101562  GigaBytes

torch.Size([16, 4])
----------------------------------------after rst
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0005311965942382812  GigaBytes
Max Memory Allocated: 0.0005397796630859375  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.000522613525390625  GigaBytes
Max Memory Allocated: 0.0005397796630859375  GigaBytes

torch.Size([9, 256])
input nodes number: 16
output nodes number: 9
edges number: 18
----------------------------------------after model layer 0 x = self.bns[i](x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0005340576171875  GigaBytes
Max Memory Allocated: 0.0005397796630859375  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0005426406860351562  GigaBytes
Max Memory Allocated: 0.0005426406860351562  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0005450248718261719  GigaBytes
Max Memory Allocated: 0.0005536079406738281  GigaBytes

----------------------------------------before model layer 1
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0005450248718261719  GigaBytes
Max Memory Allocated: 0.0005536079406738281  GigaBytes

torch.Size([9, 256])
----------------------------------------after rst
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0005555152893066406  GigaBytes
Max Memory Allocated: 0.0005583763122558594  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0005526542663574219  GigaBytes
Max Memory Allocated: 0.0005583763122558594  GigaBytes

torch.Size([3, 256])
input nodes number: 9
output nodes number: 3
edges number: 8
----------------------------------------after model layer 1 x = self.bns[i](x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0005583763122558594  GigaBytes
Max Memory Allocated: 0.0005583763122558594  GigaBytes

----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0005612373352050781  GigaBytes
Max Memory Allocated: 0.0005612373352050781  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0005621910095214844  GigaBytes
Max Memory Allocated: 0.0005650520324707031  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0005660057067871094  GigaBytes
Max Memory Allocated: 0.0005664825439453125  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0005655288696289062  GigaBytes
Max Memory Allocated: 0.0005664825439453125  GigaBytes

torch.Size([1, 2])
input nodes number: 3
output nodes number: 1
edges number: 2
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0005669593811035156  GigaBytes
Max Memory Allocated: 0.0005669593811035156  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0010170936584472656  GigaBytes
Max Memory Allocated: 0.0010652542114257812  GigaBytes

----------------------------------------before model layer 0
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0010170936584472656  GigaBytes
Max Memory Allocated: 0.0010652542114257812  GigaBytes

torch.Size([29, 4])
----------------------------------------after rst
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0010666847229003906  GigaBytes
Max Memory Allocated: 0.0010905265808105469  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0010428428649902344  GigaBytes
Max Memory Allocated: 0.0010905265808105469  GigaBytes

torch.Size([25, 256])
input nodes number: 29
output nodes number: 25
edges number: 49
----------------------------------------after model layer 0 x = self.bns[i](x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0010695457458496094  GigaBytes
Max Memory Allocated: 0.0010905265808105469  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0010933876037597656  GigaBytes
Max Memory Allocated: 0.0010933876037597656  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0010995864868164062  GigaBytes
Max Memory Allocated: 0.0011234283447265625  GigaBytes

----------------------------------------before model layer 1
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0010995864868164062  GigaBytes
Max Memory Allocated: 0.0011234283447265625  GigaBytes

torch.Size([25, 256])
----------------------------------------after rst
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0011615753173828125  GigaBytes
Max Memory Allocated: 0.0011816024780273438  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0011415481567382812  GigaBytes
Max Memory Allocated: 0.0011816024780273438  GigaBytes

torch.Size([21, 256])
input nodes number: 25
output nodes number: 21
edges number: 56
----------------------------------------after model layer 1 x = self.bns[i](x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0011644363403320312  GigaBytes
Max Memory Allocated: 0.0011816024780273438  GigaBytes

----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0011844635009765625  GigaBytes
Max Memory Allocated: 0.0011844635009765625  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0011897087097167969  GigaBytes
Max Memory Allocated: 0.0012097358703613281  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0012087821960449219  GigaBytes
Max Memory Allocated: 0.0012240409851074219  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.0012083053588867188  GigaBytes
Max Memory Allocated: 0.0012240409851074219  GigaBytes

torch.Size([17, 2])
input nodes number: 21
output nodes number: 17
edges number: 54
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.2489013671875 GB
    Memory Allocated: 0.001209259033203125  GigaBytes
Max Memory Allocated: 0.0012240409851074219  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.00021147727966308594 |0.19012796878814697 |0.42360782623291016 |0.00016355514526367188 |0.0050852298736572266 |0.002715587615966797 |
----------------------------------------------------------pseudo_mini_loss sum 2.4487123489379883
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  103
Number of first layer input nodes during this epoch:  45
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.002033710479736328  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
[Block(num_src_nodes=34, num_dst_nodes=34, num_edges=67), Block(num_src_nodes=34, num_dst_nodes=30, num_edges=78), Block(num_src_nodes=30, num_dst_nodes=24, num_edges=70)]
global src and dst nids
tensor([11, 12,  3, 16, 15,  4,  6,  7,  9, 10, 21, 22, 19,  1, 17, 14,  5, 23,
        20,  2, 18,  0,  8, 13, 32, 33, 30, 25, 29, 31, 27, 28, 24, 26])
tensor([11, 12,  3, 16, 15,  4,  6,  7,  9, 10, 21, 22, 19,  1, 17, 14,  5, 23,
        20,  2, 18,  0,  8, 13, 32, 33, 30, 25, 29, 31, 27, 28, 24, 26])
global src and dst nids
tensor([11, 12,  3, 16, 15,  4,  6,  7,  9, 10, 21, 22, 19,  1, 17, 14,  5, 23,
        20,  2, 18,  0,  8, 13, 32, 33, 30, 25, 29, 31, 27, 28, 24, 26])
tensor([11, 12,  3, 16, 15,  4,  6,  7,  9, 10, 21, 22, 19,  1, 17, 14,  5, 23,
        20,  2, 18,  0,  8, 13, 32, 33, 30, 25, 29, 31])
global src and dst nids
tensor([11, 12,  3, 16, 15,  4,  6,  7,  9, 10, 21, 22, 19,  1, 17, 14,  5, 23,
        20,  2, 18,  0,  8, 13, 32, 33, 30, 25, 29, 31])
tensor([11, 12,  3, 16, 15,  4,  6,  7,  9, 10, 21, 22, 19,  1, 17, 14,  5, 23,
        20,  2, 18,  0,  8, 13])
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.0021398067474365234
src global
[11, 12, 3, 16, 15, 4, 6, 7, 9, 10, 21, 22, 19, 1, 17, 14, 5, 23, 20, 2, 18, 0, 8, 13, 32, 33, 30, 25, 29, 31]
dst local
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]
global_2_local spend time (sec) 7.772445678710938e-05
----------------------------  graph partition start---------------------
  (6, 0)	1
  (12, 0)	1
  (23, 0)	1
  (29, 0)	1
  (6, 1)	1
  (7, 1)	1
  (12, 1)	1
  (13, 1)	1
  (19, 1)	1
  (23, 1)	1
  (29, 1)	1
  (8, 2)	1
  (10, 2)	1
  (13, 2)	2
  (14, 2)	1
  (19, 2)	2
  (21, 2)	3
  (26, 2)	1
  (5, 3)	1
  (6, 3)	1
  (9, 3)	1
  (16, 3)	1
  (21, 3)	2
  (3, 5)	1
  (6, 5)	1
  :	:
  (13, 21)	2
  (16, 21)	1
  (19, 21)	1
  (25, 21)	1
  (2, 22)	1
  (6, 22)	1
  (8, 22)	1
  (12, 22)	1
  (13, 22)	1
  (21, 22)	1
  (23, 22)	1
  (29, 22)	1
  (1, 23)	1
  (2, 23)	1
  (6, 23)	1
  (7, 23)	1
  (8, 23)	1
  (10, 23)	1
  (12, 23)	1
  (13, 23)	2
  (14, 23)	1
  (19, 23)	2
  (21, 23)	1
  (26, 23)	1
  (29, 23)	1
     source  target  weight  capacity
0         6       0       1         1
1        12       0       1         1
2        23       0       1         1
3         6       1       1         1
4         7       1       1         1
..      ...     ...     ...       ...
102      12      23       1         1
103      13      23       2         2
104      14      23       1         1
105      19      23       2         2
106      21      23       1         1

[107 rows x 4 columns]

3
({0}, {1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 19, 21, 22, 23})
after graph partition
graph partition algorithm spend time 0.02482771873474121
partition_len_list
[2, 21]
shared_neighbor_graph_partition selection method range initialization spend 0.025101423263549805
time for parepare:  7.3909759521484375e-06
local_output_nid generation:  2.6226043701171875e-06
local_in_edges_tensor generation:  0.00012683868408203125
mini_batch_src_global generation:  2.8371810913085938e-05
r_  generation:  4.124641418457031e-05
local_output_nid generation:  2.86102294921875e-06
local_in_edges_tensor generation:  0.0001316070556640625
mini_batch_src_global generation:  1.8835067749023438e-05
r_  generation:  4.4345855712890625e-05
----------------------check_connections_block total spend ----------------------------- 0.0005407333374023438
generate_one_block  0.0029141902923583984
generate_one_block  0.0013535022735595703
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0004954338073730469
gen group dst list time:  2.0503997802734375e-05
time for parepare:  1.6450881958007812e-05
local_output_nid generation:  2.1457672119140625e-06
local_in_edges_tensor generation:  0.0001862049102783203
mini_batch_src_global generation:  1.9073486328125e-05
r_  generation:  1.9073486328125e-05
local_output_nid generation:  3.0994415283203125e-06
local_in_edges_tensor generation:  0.0001232624053955078
mini_batch_src_global generation:  1.71661376953125e-05
r_  generation:  4.124641418457031e-05
----------------------check_connections_block total spend ----------------------------- 0.0005397796630859375
generate_one_block  0.0012319087982177734
generate_one_block  0.0012624263763427734
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0004646778106689453
gen group dst list time:  1.9311904907226562e-05
time for parepare:  1.049041748046875e-05
local_output_nid generation:  1.9073486328125e-06
local_in_edges_tensor generation:  0.00016880035400390625
mini_batch_src_global generation:  1.9788742065429688e-05
r_  generation:  2.1219253540039062e-05
local_output_nid generation:  3.337860107421875e-06
local_in_edges_tensor generation:  0.0001232624053955078
mini_batch_src_global generation:  1.9550323486328125e-05
r_  generation:  4.029273986816406e-05
----------------------check_connections_block total spend ----------------------------- 0.0005235671997070312
generate_one_block  0.0012271404266357422
generate_one_block  0.0012781620025634766
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.002033710479736328  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

connection checking time:  0.0010633468627929688
block generation total time  0.004999637603759766
average batch blocks generation time:  0.002499818801879883
block dataloader generation time/epoch 1.0075068473815918
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020232200622558594  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before model layer 0
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020232200622558594  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([11, 4])
----------------------------------------after rst
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020346641540527344  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.002029895782470703  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([5, 256])
input nodes number: 11
output nodes number: 5
edges number: 9
----------------------------------------after model layer 0 x = self.bns[i](x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.002037525177001953  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020422935485839844  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020437240600585938  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before model layer 1
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020437240600585938  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([5, 256])
----------------------------------------after rst
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020513534545898438  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020494461059570312  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([2, 256])
input nodes number: 5
output nodes number: 2
edges number: 4
----------------------------------------after model layer 1 x = self.bns[i](x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020542144775390625  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.002056121826171875  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.002056598663330078  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.002060413360595703  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020599365234375  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([1, 2])
input nodes number: 2
output nodes number: 1
edges number: 1
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020608901977539062  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020241737365722656  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before model layer 0
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020241737365722656  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([28, 4])
----------------------------------------after rst
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020737648010253906  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020499229431152344  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([25, 256])
input nodes number: 28
output nodes number: 25
edges number: 50
----------------------------------------after model layer 0 x = self.bns[i](x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0020766258239746094  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0021004676818847656  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0021066665649414062  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before model layer 1
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0021066665649414062  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([25, 256])
----------------------------------------after rst
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0021686553955078125  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0021486282348632812  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([21, 256])
input nodes number: 25
output nodes number: 21
edges number: 58
----------------------------------------after model layer 1 x = self.bns[i](x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0021715164184570312  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0021915435791015625  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.002196788787841797  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.002215862274169922  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.0022153854370117188  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([17, 2])
input nodes number: 21
output nodes number: 17
edges number: 55
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.2508544921875 GB
    Memory Allocated: 0.002216339111328125  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.00017762184143066406 |0.0004984140396118164 |0.010097980499267578 |0.000102996826171875 |0.0031862258911132812 |0.0013549327850341797 |
----------------------------------------------------------pseudo_mini_loss sum 0.26495376229286194
Total (block generation + training)time/epoch 1.0397717952728271
Training time/epoch 0.03197455406188965
Training time without block to device /epoch 0.030977725982666016
Training time without total dataloading part /epoch 0.02812933921813965
load block tensor time/epoch 0.0003552436828613281
block to device time/epoch 0.0009968280792236328
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 1 |
Number of nodes for computation during this epoch:  92
Number of first layer input nodes during this epoch:  39
